# WatGPT
The Military University of Technology in Warsaw chatbot

## Installation

To install and set up the project, you can use the Python Poetry package manager. Follow the steps below:

**NOTE**: These instructions are tailored for Linux systems.

1. Make sure you have Python installed on your system. You can download it from the official Python website: [python.org](https://www.python.org/downloads/).

2. Install Poetry by running the following command in your terminal or command prompt:

   ```bash
   curl -sSL https://install.python-poetry.org | python3 -
    ```

   Then, export the Poetry binary directory to your system's PATH:
   ```bash
   export PATH="$HOME/.local/bin:$PATH"
    ```
   Optionaly you can add this line to your `~/.bashrc`.

   Then you can run the following command to apply the changes:
   ```bash
   source ~/.bashrc
   ```

   Also you can install `poetry-exec-plugin` to enable running scripts from the `pyproject.toml` file:
   ```bash
   poetry self add poetry-exec-plugin
   ```

3. Clone the repository to your local machine:

   ```bash
   git clone https://github.com/KubiakJakub01/WatGPT.git
   cd WatGPT
    ```

4. Install the project dependencies using Poetry:

   ```bash
   poetry install --with dev
    ```

5. To activate the virtual environment, run the following command:

   ```bash
   source $(poetry env info --path)/bin/activate
    ```
    Optionaly you can add the following line to your `.bashrc`:
    ```bash
    alias activate="source $(poetry env info --path)/bin/activate"
    ```
    Then you can activate the virtual environment by running:
    ```bash
    activate
    ```
  
6. Setting Up Pre-commit Hooks:

	To ensure code quality and consistency, you can set up pre-commit hooks using the `pre-commit` tool. Follow these steps:

	```bash
	pre-commit install
	```

	Now, the pre-commit hooks will automatically run on every commit, ensuring that your code adheres to the specified standards.


## Running the Code
Make sure to activate the poetry environment before running these scripts:
```bash
source $(poetry env info --path)/bin/activate
```
or run command with `poetry run` ex.:
```bash
poetry run python -m watgpt.scripts.create_chunk_db
```

### Environment Variables

Create a `.env` file in the project root directory and add the following environment variables:
```bash
GROQ_API_KEY=your_api_key
```

### Docker

To run the project in a Docker container, you can use the provided Dockerfile. Follow these steps:
```bash
docker build -t watgpt .
```

### Docker Compose

To run the project with Docker Compose, use the following command:
```bash
docker compose up
```
It will sequentially:
####1. Run the create_db service that will:
- Create chunks.db (SQLite database).
- Extract text from PDFs in wat_data/ and store in pdf_chunks.
- Scrape timetable data from the provided URL and populate timetable tables.

####2. Run the scrape service that will:
- Scrape all the timetable data for each group and put it into SQLite database
- Scrape text from websites in https://www.wcy.wat.edu.pl/  domain and put it into SQLite database
- Download pdf files from websites in https://www.wcy.wat.edu.pl/ domain extract text from them and put it into SQLite database

####3. Run the create_vector_db service that will:
- Fetch all the text data from SQLite database convert it to vector embeddings and store it in Vector database

####4. Run the api service that will:
- Setup FastAPI and expose endpoints for using the chat

After running docker-compose up for the first time if you changed something in code and don't wanna to create databases and scrape data again, to rerun the app you can just run:
```bash
docker-compose up api
```


### API
Provides a REST API to interact with the LLM Engine.
1. **POST /chat**

	- **Description:**
Handles chat queries by forwarding the input query to the LLM engine and returning the generated response.
	- **Default address:**
Currently the default address and port are http://localhost:8000/chat
	- **Request Body:**
	A JSON object with the following property:
		- query (string): The text query to be processed.
		- Example request:
		```json
		{
  			"query": "Kiedy jest 1 termin zimowej sesji poprawkowej dla studentow stacjonarynch cywilnych?"
		}
		```
	- **Response Body:**
	A JSON object with the following property:
		- response (string): The response generated by the LLM.
		- Example response:
		```json
		{
  			"response": "Na podstawie dostarczonego harmonogramu roku akademickiego 2024/2025, termin 1 terminu zimowej sesji poprawkowej dla studentów stacjonarnych cywilnych jest następujący:\n\n* Zamknięcie I terminu protokołów w USOS: 16 lutego 2025 roku\n* Zamknięcie protokołów w USOS dla I roku studiów wojskowych: 20 lipca 2025 roku\n\nW związku z tym, że student stacjonarny cywilny nie jest zobowiązany do odbywania służby wojskowej, jego termin 1 terminu zimowej sesji poprawkowej to 16 lutego 2025 roku.\nŹródła: ['\\n            zalacznik_do_decyzji_rektora_nr_173_rkr_2024_z_dnia_11_czerwca_-_harmonogram_roku_akademickiego_2024_2025.pdf - https://www.wcy.wat.edu.pl/pl/wydzial/ksztalcenie/informacje-studenci/kalendarz-akademicki \\n            - https://www.wcy.wat.edu.pl/system/files_force/documents/2237/zalacznik_do_decyzji_rektora_nr_173_rkr_2024_z_dnia_11_czerwca_-_harmonogram_roku_akademickiego_2024_2025.pdf?download=1\\n            ', '\\n            regulamin_studiow.pdf - https://www.wcy.wat.edu.pl/pl/wydzial/ksztalcenie/informacje-studenci/regulaminy \\n            - https://www.wcy.wat.edu.pl/system/files_force/documents/249/regulamin_studiow.pdf?download=1\\n            ', '\\n            zal._nr_3_organizacja_zajec_w_roku_akademickim_2024_2025_na_jednolitych_studiach_magisterskich.pdf - https://www.wcy.wat.edu.pl/pl/wydzial/ksztalcenie/informacje-studenci/kalendarz-akademicki \\n            - https://www.wcy.wat.edu.pl/system/files_force/documents/2243/zal._nr_3_organizacja_zajec_w_roku_akademickim_2024_2025_na_jednolitych_studiach_magisterskich.pdf?download=1\\n            ']"
		}
		```
	- **Error Handling:**
		If an error occurs, the API returns a status code of 500 along with an error message.

2. **GET /health**

	- **Description:**
A simple health check endpoint to verify that the API is up and running.
	- **Default address:**
Currently the default address and port are http://localhost:8000/health
	- **Response Body:**
	A JSON object indicating the service status.
		- Example Response:
		```json
		{
  			"status": "ok"
		}
		```

### Chunk Database

1. **Create Chunk Database**
	Run the setup script to create SQLite database
	```bash
	python3 -m watgpt.scripts.create_sql_db
	```
	This will:
	- Create chunks.db (SQLite database). and create default tables

### Scraper settings
1. **Settings for scrapy:**
For scraping data we are using scrapy library, you can configure what to scrape in *constants.py* file by
changing the following properties:
```bash
# ---- Values for Scrapy
ALLOWED_PATHS = (r'wydzial/ksztalcenie/',)
DENIED_PATHS = (r'karty-informacyjne-przedmiotow',r'/kursy-mon')
DENIED_EXTENSIONS = ['jpg', 'jpeg', 'png', 'gif', 'webp', 'bmp']
TARGET_GROUPS = "WCY24IV1N2"
```
	- **ALLOWED_PATHS** - checks if given address contain specified string if it does then it will scrape it, so for the example values it will scrape data and files from:
		- https://www.wcy.wat.edu.pl/pl/wydzial/ksztalcenie/informacje-studenci/kalendarz-akademicki

	but it wont scrape data from:

		- https://www.wcy.wat.edu.pl/wydzial/aktualnosci/wszystkie
		
	- **DENIED_PATHS** - checks if given address contain specified string if it does then it will **not** scrape it, so for so for the example values it will not scrape data and files from:
		- https://www.wcy.wat.edu.pl/wydzial/ksztalcenie/kursy-mon

	- **DENIED_EXTENSIONS** - checks if file have one of the listed extensions if yes then it will not download it

	- **TARGET_GROUPS** - list of groups for scraping timetable data, if list is empty it will scrape data for ALL the groups (it will take a while)
	
2. **Running the scrape script**:
To run the script for scraping data run the following script:
```bash
python3 -m watgpt.scripts.scrape
``` 

### Vector Database

1. **Create Vector Database**:
	To create the vector database, run the following script:
	```bash
	python -m watgpt.scripts.create_vector_db
	```
	This will:
	- Create `vectors.db` (SQLite database).
	- Convert text chunks from `chunks.db` into vector representations.
	- Store these vectors in the `vectors` table.

2. **Query Vector Database**:
	To query the vector database, use the following script:
	```bash
	python -m watgpt.scripts.query_vector_db -h
	```
	This script will:
	- Accept a query text input.
	- Convert the query into a vector.
	- Find and return the most similar text chunks from the `vectors` table.


## Database Structure

This project uses SQLAlchemy ORM to define and manage the database. The schema is created automatically by the SqlDB class using models defined with SQLAlchemy’s modern, typed API.

### Tables

####Chunks Table
Stores text chunks extracted from websites and PDF files.

Schema:
```sql
CREATE TABLE chunks
(
		chunk_id INTEGER PRIMARY KEY AUTOINCREMENT,
		source_url TEXT,
		file_url TEXT,
		title TEXT,
		content TEXT NOT NULL,
		date TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

- chunk_id: Auto-incrementing unique ID.
- source_url: URL of text that data was scraped from or URL where file was downloaded
- file_url: File path of the source file (only for files)
- title: Title or section heading
- content: Extracted text chunk.
- date: Timestamp of creation.

####BlockHours Table
Defines lecture block times.

Schema:
```sql 
CREATE TABLE block_hours (
	block_id TEXT PRIMARY KEY,
	start_time TEXT NOT NULL,
	end_time TEXT NOT NULL
	);
```

- block_id: Identifier for the block (e.g., "block1").
- start_time: Start time (e.g., "08:00").
- end_time: End time (e.g., "09:35").

####Groups Table
Stores student group information.

Schema:
```sql 
CREATE TABLE groups (
	group_id INTEGER PRIMARY KEY AUTOINCREMENT,
	group_code TEXT NOT NULL UNIQUE
); 
```
- group_id: Unique group identifier.
- group_code: Group code (e.g., "WCY24IV1N2").

####Teachers Table
Stores instructor details.

Schema:
```sql 
CREATE TABLE teachers (  
		teacher_id INTEGER PRIMARY KEY AUTOINCREMENT,
		full_name TEXT NOT NULL,
		short_code TEXT
); 
```

- teacher_id: Unique teacher identifier.
- full_name: Teacher's full name.
- short_code: Optional abbreviation.

####Courses Table
Stores course metadata.

Schema:
```sql 
CREATE TABLE courses (
		course_id INTEGER PRIMARY KEY AUTOINCREMENT,
		course_code TEXT NOT NULL,
		course_name TEXT 
); 
```
- course_id: Unique course identifier.
- course_code: Short code for the course.
- course_name: Full name (optional).

####Lessons Table
Represents scheduled lessons, linking groups, courses, teachers, and block hours.

Schema:
```sql 
CREATE TABLE lessons (
lesson_id INTEGER PRIMARY KEY AUTOINCREMENT,
group_id INTEGER NOT NULL,
course_id INTEGER NOT NULL,
teacher_id INTEGER,
block_id TEXT NOT NULL,
lesson_date TEXT NOT NULL,
room TEXT,
building TEXT,
info TEXT,
created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
); 
```

- lesson_id: Unique lesson identifier.
- group_id: Foreign key referencing groups.
- course_id: Foreign key referencing courses.
- teacher_id: Foreign key referencing teachers (optional).
- block_id: Foreign key referencing block_hours.
- lesson_date: Date of the lesson (format "YYYY-MM-DD" or "YYYY_MM_DD").
- room: Room number (optional).
- building: Building number (optional).
- info: Additional lesson details.
- created_at: Creation timestamp.
- updated_at: Last update timestamp.

### Database Initialization and Operations

The SqlDB class (in watgpt/db/sql_db.py) manages the SQLite database located at the path specified by CHUNKS_DATABASE_FILE. When an instance of SqlDB is created, it:
- Connects to the SQLite database using SQLAlchemy's create_engine.
- Calls init_db() to create all tables as defined in the models (Chunk, BlockHours, Group, Teacher, Course, Lesson).
- Invokes fill_block_hours() to insert default block time records if they are not already present.

#### Key Operations Provided by SqlDB
- create_chunk(source_url, file_url, title, content): Inserts a new chunk and returns its ID.
- fetch_all_chunks(): Retrieves all PDF chunks.
- insert_group(group_code): Inserts a group if it doesn't exist and returns its ID.
- insert_teacher(full_name, short_code): Inserts a teacher and returns its ID.
- insert_course(course_code, course_name): Inserts a course and returns its ID.
- insert_lesson(...): Inserts a lesson record and returns its ID.
- fetch_lessons_by_group(group_code): Retrieves lessons for a specific group.
- fetch_lessons_namedtuple(group_code): Retrieves lessons as named tuples for easier inspection.

### Checking the Database

You can inspect the SQLite database using the SQLite CLI or a GUI tool like DB Browser for SQLite. For example, open a terminal and run:
bash sqlite3 databases/chunks.db 
Then, you can execute queries such as:
```sql
SELECT * FROM chunks LIMIT 5; -- View the first 5 PDF chunks
```
```sql
SELECT * FROM lessons WHERE group_id = 1; -- View lessons for group_id = 1
```

This structure leverages SQLAlchemy’s ORM for database interactions, ensuring that the schema is created and populated automatically when the application starts.